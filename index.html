<!DOCTYPE html>
<html>

<head lang="en">
    <meta charset="UTF-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>NICE</title>

    <meta name="description" content="NICE">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!--FACEBOOK-->
    <!-- <meta property="og:image" content="img/twitter-card.jpg"> -->
    <!-- <meta property="og:image:type" content="image/png"> -->
    <!-- <meta property="og:image:width" content="1024"> -->
    <!-- <meta property="og:image:height" content="512"> -->
    <meta property="og:type" content="website" />
    <meta property="og:url" content="https://nsidn98.github.io/NICE/" />
    <meta property="og:title" content="NICE" />
    <meta property="og:description"
        content="Project page for NICE: Robust Scheduling through Reinforcement Learning-Guided Integer
        Programming." />

    <!--TWITTER-->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:site" content="https://nsidn98.github.io/NICE/" />
    <meta name="twitter:title" content="NICE" />
    <meta name="twitter:description"
        content="Project page for NICE: Robust Scheduling through Reinforcement Learning-Guided Integer
        Programming." />



    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.css">
    <link rel="stylesheet" href="css/app.css">

    <link rel="stylesheet" href="css/bootstrap.min.css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-5H2C4DFSMD"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag() { dataLayer.push(arguments); }
        gtag('js', new Date());

        gtag('config', 'G-5H2C4DFSMD');
    </script> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/codemirror/5.8.0/codemirror.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.5.3/clipboard.min.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                NICE: Robust Scheduling through Reinforcement Learning <br>
                Guided Integer Programming. </br>
                <small>
                    AAAI 2022
                </small>
            </h2>

        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://www.linkedin.com/in/luke-kenworthy-7909b2163/">
                            Luke Kenworthy
                        </a>
                        </br>MIT-Air Force AI Accelerator
                    </li>
                    <li>
                        <a href="https://nsidn98.github.io">
                            Siddharth Nayak
                        </a>
                        </br>MIT
                    </li>
                    <li>
                        <a href="https://www.linkedin.com/in/chris-chin-9702a05b/">
                            Christopher Chin
                        </a>
                        </br>MIT
                    </li>
                    <li>
                        <a href="https://www.mit.edu/~hamsa/index.html">
                            Hamsa Balakrishnan
                        </a>
                        </br>MIT
                    </li>
                </ul>

                <!-- *denotes equal contribution -->
            </div>
        </div>


        <div class="row">
            <div class="col-md-5 col-md-offset-3 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://arxiv.org/abs/2109.12171">
                            <image src="img/nice_paper_png.png" height="60px">
                                <h4><strong>Paper</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://github.com/nsidn98/NICE">
                            <image src="img/github.png" height="60px">
                                <h4><strong>Code</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.dropbox.com/s/ng4bwkschxfovz6/NICE%20Slides.pptx?dl=0">
                            <image src="img/ppt.png" height="60px">
                                <h4><strong>Slides</strong></h4>
                        </a>
                    </li>
                    <li>
                        <a href="https://www.youtube.com/watch?v=ooj9E-endGc">
                            <image src="img/yt.png" height="60px">
                                <h4><strong>YouTube</strong></h4>
                        </a>
                    </li>
                    
                    <li>
                        <a href="https://www.dropbox.com/s/768l2sqmnxsf28o/NICE%20poster.pdf?dl=0">
                            <image src="img/poster.png" height="60px">
                                <h4><strong>Poster</strong></h4>
                        </a>
                    </li>

                </ul>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                    <p class="text-justify">
                        Integer programs provide a powerful abstraction for representing 
                        a wide range of real-world scheduling problems. Despite 
                        their ability to model general scheduling problems, 
                        solving large-scale integer programs (IP) remains a computational 
                        challenge in practice. The incorporation of more complex objectives 
                        such as robustness to disruptions further exacerbates the computational 
                        challenge. We present <b>NICE</b>  (Neural network IP Coefficient Extraction), 
                        a novel technique that combines reinforcement learning and 
                        integer programming to tackle the problem of robust scheduling. 
                        More specifically, NICE uses reinforcement learning to approximately 
                        represent complex objectives in an integer programming formulation.  
                        We use NICE to determine assignments of pilots to a flight 
                        crew schedule so as to reduce the impact of disruptions. 
                        We compare NICE with (1) a baseline integer programming 
                        formulation that produces a feasible crew schedule, and 
                        (2) a robust integer programming formulation that explicitly 
                        tries to minimize the impact of disruptions. Our experiments 
                        show that, across a variety of scenarios, NICE produces 
                        schedules resulting in 33% to 48% fewer disruptions than 
                        the baseline formulation. Moreover, in more severely 
                        constrained scheduling scenarios in which the robust integer 
                        program fails to produce a schedule within 90 minutes, NICE 
                        is able to build robust schedules in less than 2 seconds on average.
                        <br>
                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Motivation
                </h3>
                <!-- <image src="img/fig_1.jpg" class="img-responsive" alt="overview"><br> -->
                    <p class="text-justify">
                        <u><b>Baseline Integer Programming (IP)</b></u>: these can be easily 
                        constructed for simpler crew-scheduling problems due to 
                        the ease in encoding the objectives and constraints. But 
                        these methods fail when there is uncertainty. Specifically, 
                        if there are disruptions in the flights, a new solution 
                        with new assignments has to be created. A simple objective 
                        function for assigning pilots to flights could be: 
                        <br> 
                            <center>
                                <img src="https://latex.codecogs.com/svg.image?\max&space;\sum\limits_{i\in&space;I}\sum\limits_{s\in&space;S}&space;X_{is}" 
                                title="\max \sum\limits_{i\in I}\sum\limits_{s\in S} X_{is}" 
                                class="center" alt="Baseline IP objective"/>
                            </center>
                        <br>
                        where we maximize the number of pilots getting assigned 
                        to slots in flights. Here ùêº is the set of pilots, ùëÜ is 
                        the set of slots in flights.
                        <br>
                        <br>

                        <u><b>Robust Buffer Formulation</b></u>: one can use a 
                        more sophisticated IP formulation to account for these 
                        disruptions. To alleviate the effect of disruptions, one 
                        could try to maximize the buffers between successive flights 
                        the pilots get assigned to so that any overflow caused due 
                        to delays in flights will have some buffer time. Here, 
                        one could use an objective function like: 
                        <br> 
                            <center>
                                <img src="https://latex.codecogs.com/svg.image?\max&space;\sum\limits_{i\in&space;I}\sum\limits_{f,f'\in&space;F\times&space;F}&space;b_{iff'}B_{iff'}" 
                                title="\max \sum\limits_{i\in I}\sum\limits_{f,f'\in F\times F} b_{iff'}B_{iff'}" 
                                class="center" alt="Robust buffer IP objective"/>
                            </center>
                        <br>
                        where the objective function is penalizes for having 
                        smaller buffers. But as the problem becomes more complex, 
                        the time required to get the solution increases and quickly 
                        becomes intractable. Here ùêπ is the set of flights, ùëè_(ùëñùëìùëì^‚Ä≤ )  
                        is the buffer penalty.
                        <br>
                        <br>

                        <u><b>Reinforcement Learning (RL)</b></u>: Another 
                        possible solution would be to use RL to create schedules 
                        where the flights are shown sequentially in chronological 
                        order and the agent has to choose pilots. Here, the agent 
                        can be rewarded according to whatever objective function 
                        we want to optimize. Although, this works well, the IP 
                        methods perform better to give a solution in a reasonable 
                        amount of time. 
                        <br>
                        <br>

                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>
                <p class="text-justify">
                    <u><b>Knowledge Distillation</b></u>: <a href="https://arxiv.org/abs/1503.02531">Hinton et al.
                        (2015)</a> show 
                    that the probabilities in a neural network‚Äôs output layer 
                    carries useful information even if only the maximum probability 
                    value is used for downstream tasks like classification. Instead 
                    of letting the RL agent take actions in the environment, 
                    we use the probability distribution over the choice of pilots 
                    to guide the IP.
                    <br>


                    <center>
                        <figure>
                            <image src="img/rl_mdp.png" class="center" alt="The MDP for RL agent" height="340"/>
                            <figcaption><b><br>Fig 1:</b> A rough MDP for the RL agent. The RL agent gives a probability 
                            distribution over the pilots which is used by NICE to boost the integer programming formulation.</figcaption>
                        </figure>
                    </center>

                    <br>
                    The objective function is modified to:
                    <br>
                    <br> 
                            <center>
                                <img src="https://latex.codecogs.com/svg.image?\max&space;\sum\limits_{i\in&space;I}\sum\limits_{s\in&space;S}&space;a_{is}X_{is}" 
                                title="\max \sum\limits_{i\in I}\sum\limits_{s\in S} a_{is}X_{is}" 
                                class="center" alt="Modified NICE IP objective"/>
                            </center>
                    <br>
                    where ùëé_ùëñùë† are the probabilities for assigning pilot ùëñ to slot ùë†. 
                    The probability values are obtained from the final layer of the RL agent‚Äôs network.
                    
                    <br>
                    <br>
                    <br>

                    <u><b>Probability Weight Extraction</b></u>: Two different 
                    methods are used to extract the weights from the RL agent
                    <br>
                    
                    <ol>
                        <li>
                            <u><b>Blank State Method</b></u>: This approach exploits the 
                            fact that the probability weights for the pilots produced by 
                            the first slot do not depend on any previous actions taken. 
                            Here, each slot is treated as the first scheduled slot. To 
                            do so, for each slot in the fixed order a new RL agent with 
                            the same underlying neural network is initialized cutting out 
                            all the states that occur before extracting the probability 
                            values ùëé_ùëñùë†
                            <br>
                        </li>
                    
                        <li>
                            <u><b>Monte Carlo Method</b></u>: The scheduler is run ùëõ times, 
                            shuffling the order of slots each time. Then, the probability 
                            values from the output layer are averaged across the ùëõ runs. 
                            These coefficients are then passed to the IP solver to obtain 
                            the NICE-generated schedule.
                        </li>
                    </ol>
                    <br>
                    <br>


                <!-- <figure>
                    <image src="img/fig_2.jpg" class="img-responsive" onmouseover="this.src='img/fig_2_hover.jpg'"
                        onmouseout="this.src='img/fig_2.jpg'" alt="" />
                    <figcaption><b><br>Method overview.</b> Hover mouse pointer to see details.</figcaption>
                </figure> -->
                <center>
                    <figure>
                        <image src="img/extract-labeled.png" class="center" alt="The weight extraction method" height="450"/>
                        <figcaption><b><br>Fig 2:</b> The Monte Carlo weight extraction method. Once we train our network, 
                            we run the scheduler n times, shuffling the order of slots each time. We then average the 
                            probability values in the output layer across the n runs over pilots and slots to obtain
                            our NICE coefficients. Finally, we pass these coefficients to the IP solver to obtain our 
                            NICE-generated schedule.</figcaption>
                    </figure>
                </center>
                
                <br>
                <br>

                <center>
                    <figure>
                        <image src="img/NICE_psuedocode.png" class="center" alt="A rough pseudocode" height="600"/>
                        <!-- <figcaption><b><br>Pseudocode for NICE.</b></figcaption> -->
                    </figure>
                </center>

            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Experiments and Results
                </h3>
                <!-- <image src="img/fig_1.jpg" class="img-responsive" alt="overview"><br> -->
                    <p class="text-justify">
                        We perform the experiments as follows:
                        <ul>
                            <li> Generate one week's worth of flights </li>
                            <li> Schedule with baseline IP, RL scheduler, buffer IP and NICE</li>
                            <li> One day into the schedule delay f% of the flights that had not already left</li>
                            <li> Fix delays with disruption minimizing IP</li>
                            <li> Count the disruptions with each scheduling method</li>
                        </ul>

                        <br>

                        <center>
                            <figure>
                                <image src="img/res1.png" class="center" alt="The weight extraction method" height="200"/>
                                <figcaption><b><br>Table 1</b>: With scheduling density same as the training dataset, 
                                    both NICE and Buffer IP take &#60 0.85 seconds on average. </figcaption>
                            </figure>
                        </center>

                        <br>

                        <center>
                            <figure>
                                <image src="img/res2.png" class="center" alt="The weight extraction method" height="200"/>
                                <figcaption><b><br>Table 2</b>: With scheduling density twice as the training dataset, 
                                    NICE gives a solution in 1.85-1.90 seconds on average whereas Buffer IP fails to 
                                    produce even a single schedule timing out after 90 minutes.
                                </figcaption>
                            </figure>
                        </center>

                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Conclusions
                </h3>
                    <p class="text-justify">
                        <ul>
                            <li> 
                                NICE uses reinforcement learning to approximate 
                                and simplify computationally difficult integer 
                                programming problems. It leverages the knowledge 
                                learned by the RL agent along with utilizing the 
                                global outlook of the integer programming.
                            </li>

                            <li> 
                                NICE is able to produce schedules significantly 
                                better than the ones obtained by baseline integer 
                                programming formulations
                            </li>

                            <li> 
                                NICE is highly generalizable and can be used 
                                whenever there is an isomorphism between an 
                                integer program and a reinforcement learning solution
                            </li>
                        </ul>
                        <br>
                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Video at AAAI 2022
                </h3>

                <br>
                <p align="center">
                <div class="embed-responsive embed-responsive-16by9">
                    <!-- width="500" height="281" -->
                    <iframe width="560" height="315" src="https://www.youtube.com/embed/ooj9E-endGc" 
                    title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen></iframe>
<!--                     https://www.youtube.com/watch?v=dQw4w9WgXcQ -->
                </div>

                </p>

                <br> Presented at the AAAI 2022 <a href="https://aaai.org/Conferences/AAAI-22/">Main track</a>.
                <br>
                <table align=center width=800px>
                    <br>
                    <tr>
                        <center>
                            <span style="font-size:22px">&nbsp;<a
                                    href='https://www.dropbox.com/s/ng4bwkschxfovz6/NICE%20Slides.pptx?dl=0'>[Slides]</a>
                </table>


                <object width="800" height="500" type="application/pdf" data="img/nice_slides.pdf?#zoom=60&scrollbar=0&toolbar=0&navpanes=0">
                    <p>Insert your error message here, if the PDF cannot be displayed.</p>
                </object>

            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Citation
                </h3>
                <br />If you find our code or datasets useful in your research, please cite the following:
                <br />
                <br />
                <div class="form-group col-md-12 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" rows="13" readonly>
@article{DBLP:journals/corr/abs-2109-12171,
    author    = {Luke Kenworthy and Siddharth Nayak and Christopher Chin and Hamsa Balakrishnan},
    title     = {{NICE:} Robust Scheduling through Reinforcement Learning-Guided Integer Programming},
    journal   = {CoRR},
    volume    = {abs/2109.12171},
    year      = {2021},
    url       = {https://arxiv.org/abs/2109.12171},
    eprinttype = {arXiv},
    eprint    = {2109.12171},
    timestamp = {Mon, 04 Oct 2021 17:22:25 +0200},
    biburl    = {https://dblp.org/rec/journals/corr/abs-2109-12171.bib},
    bibsource = {dblp computer science bibliography, https://dblp.org}
    }                        
                    </textarea>
                </div>
                <br />
                <br />
                <br />
                <div class="form-group col-md-12 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" rows="6" readonly>
@mastersthesis{Chin2021,
    author  = "Christopher Ho-Yen Chin",
    title   = "Disruptions and Robustness in Air Force Crew Scheduling",
    school  = "MIT",
    year    = "2021"
    }
                    </textarea>
                </div>
                <br />
                <br />
                <div class="form-group col-md-12 col-md-offset-0">
                    <textarea id="bibtex" class="form-control" rows="6" readonly>
@mastersthesis{Nayak2022,
    author  = "Siddharth Nagar Nayak",
    title   = "Learning-based Scheduling",
    school  = "MIT",
    year    = "2022"
    }
                    </textarea>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Related Links
                </h3>
                <p class="text-justify">
                    <ol>

                        <li>
                            Knowledge Distillation by  
                            <a href="https://arxiv.org/abs/1503.02531">Hinton et al.
                            (2015)</a>, where the authors show the importance of the knowledge contained 
                            in the final layer of neural networks.<br />
                        </li>
                        
                        <li>
                            Reinforcement learning based methods for scheduling by <a href="https://dspace.mit.edu/handle/1721.1/145097">Siddharth Nayak
                                (2022)</a>.<br />
                        </li>

                        <li>
                            The buffer formulation was introduced by 
                            <a href="https://dspace.mit.edu/handle/1721.1/139538">Christopher Chin.
                            (2021)</a>, for the robust crew-scheduling problem.<br />
                        </li>

                        <li>
                            Integer programming formulation for different 
                            objective functions was introduced by <a href="https://hdl.handle.net/1721.1/139080">Matthew Koch 
                                (2021)</a>.<br />
                        </li>

                        <li>
                            <a href="https://vimeo.com/476994227/cd722a770a"> Talk</a> by Christopher Chin on AI-assisted Optimization 
                            of Schedules.<br />
                        </li>
                        <br />
                    </ol>
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Acknowledgements
                </h3>
                <p class="text-justify">
                    <br />This research was sponsored by the United
                    States Air Force Research Laboratory and was accomplished
                    under Cooperative Agreement Number FA8750-19-2-1000.
                    The views and conclusions contained in this document are
                    those of the authors and should not be interpreted as 
                    representing the official policies, either expressed or implied,
                    of the United States Air Force or the U.S. Government.
                    The U.S. Government is authorized to reproduce and distribute 
                    reprints for Government purposes notwithstanding
                    any copyright notion herein.
                    <br />
                    <br /> This website template was borrowed from <a href="http://mgharbi.com/">Micha√´l Gharbi</a> and
                    <a href="https://www.matthewtancik.com">Matthew Tannick</a>.
                </p>
            </div>
        </div>
    </div>





</body>

</html>
